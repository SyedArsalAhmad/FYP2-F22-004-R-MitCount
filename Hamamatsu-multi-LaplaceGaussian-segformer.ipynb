{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-12T13:17:10.886987Z",
     "iopub.status.busy": "2023-06-12T13:17:10.886578Z",
     "iopub.status.idle": "2023-06-12T13:17:10.892557Z",
     "shell.execute_reply": "2023-06-12T13:17:10.891529Z",
     "shell.execute_reply.started": "2023-06-12T13:17:10.886946Z"
    }
   },
   "outputs": [],
   "source": [
    "import os   # Importing necessary Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:17:08.805798Z",
     "iopub.status.busy": "2023-06-12T13:17:08.805379Z",
     "iopub.status.idle": "2023-06-12T13:17:08.844820Z",
     "shell.execute_reply": "2023-06-12T13:17:08.844002Z",
     "shell.execute_reply.started": "2023-06-12T13:17:08.805767Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:11:20.098184Z",
     "iopub.status.busy": "2023-06-12T13:11:20.097273Z",
     "iopub.status.idle": "2023-06-12T13:11:20.325891Z",
     "shell.execute_reply": "2023-06-12T13:11:20.325044Z",
     "shell.execute_reply.started": "2023-06-12T13:11:20.098137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"/kaggle/input/mitosis-and-non-mitosis-Hamamatsu\"))   ## Checking the length is as it should be 2400, 1200 for normal image and 1200 for masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:11:30.237375Z",
     "iopub.status.busy": "2023-06-12T13:11:30.237008Z",
     "iopub.status.idle": "2023-06-12T13:11:30.245956Z",
     "shell.execute_reply": "2023-06-12T13:11:30.244992Z",
     "shell.execute_reply.started": "2023-06-12T13:11:30.237347Z"
    }
   },
   "outputs": [],
   "source": [
    "t = os.listdir(r\"/kaggle/input/mitosis-and-non-mitosis-Hamamatsu\")   ## Get Image names of masks\n",
    "image_names = [image.split(\".\")[0] for image in t if \"not\" in image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:11:31.372197Z",
     "iopub.status.busy": "2023-06-12T13:11:31.371813Z",
     "iopub.status.idle": "2023-06-12T13:11:31.377572Z",
     "shell.execute_reply": "2023-06-12T13:11:31.376617Z",
     "shell.execute_reply.started": "2023-06-12T13:11:31.372168Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(image_names)):   ## Get image names of all\n",
    "    image_names[i] = image_names[i].replace(\"_not_mitosis\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = \"/kaggle/input/mitosis-and-non-mitosis-Hamamatsu/\" + image_names[0]\n",
    "u = u + \"_not_mitosis.jpg\"\n",
    "Image.open(u)   ## Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:17:17.786089Z",
     "iopub.status.busy": "2023-06-12T13:17:17.785697Z",
     "iopub.status.idle": "2023-06-12T13:18:27.626016Z",
     "shell.execute_reply": "2023-06-12T13:18:27.624978Z",
     "shell.execute_reply.started": "2023-06-12T13:17:17.786058Z"
    }
   },
   "outputs": [],
   "source": [
    "dictt = {}\n",
    "\n",
    "\n",
    "lower = np.array([0, 3, 240])  ## Each of these represent different colors. This is White's low range\n",
    "upper = np.array([255, 255, 255]) ## White top range\n",
    "lower1 = np.array([22, 93, 0]) ## Represents the yellow color start\n",
    "upper1 = np.array([45, 255, 255]) ## Represent yellow color end range\n",
    "for i in range(len(image_names)):\n",
    "    \n",
    "    u = \"/kaggle/input/mitosis-and-non-mitosis/\" + image_names[i]\n",
    "    blwhite = u + \"_mitosis.jpg\"   ## Uploading images to mask\n",
    "    al = cv2.imread(blwhite)\n",
    "    \n",
    "    mask = cv2.inRange(al, lower, upper) ## Once again making sure masks are rightly assigned\n",
    "    \n",
    "    color = u + \"_not_mitosis.jpg\"\n",
    "    al = cv2.imread(color)\n",
    "   \n",
    "    image = cv2.cvtColor(al, cv2.COLOR_BGR2HSV)  ## First convert to HSV\n",
    "    mask1 = cv2.inRange(image, lower1, upper1)  ## Masks will be created, all image will be black. The yellow range will become White\n",
    "    mask1[mask>0] = 120   ## In the masks created out of non mitotic images, the white dots from mitotic images become greyish 120\n",
    "    tr = Image.fromarray(mask1)\n",
    "    #tr.show()\n",
    "    dictt[image_names[i]] = tr  ## Saved according to name in dictionary\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:18:27.628317Z",
     "iopub.status.busy": "2023-06-12T13:18:27.627754Z",
     "iopub.status.idle": "2023-06-12T13:18:27.634647Z",
     "shell.execute_reply": "2023-06-12T13:18:27.633759Z",
     "shell.execute_reply.started": "2023-06-12T13:18:27.628285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:18:27.636688Z",
     "iopub.status.busy": "2023-06-12T13:18:27.635848Z",
     "iopub.status.idle": "2023-06-12T13:18:27.674040Z",
     "shell.execute_reply": "2023-06-12T13:18:27.673160Z",
     "shell.execute_reply.started": "2023-06-12T13:18:27.636656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABgMAAAVgCAAAAABHrnJzAAAJNUlEQVR4nO3dwY6CMBRA0eJX9xP4684CIxN0nKSW8J49Z6GQuOiql6eipQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHCV5eoFAHyjtj1F32Ojrw8gobYfxt5lb1cvAODrtD+O49EAgMHam7NgNABgrOOmHzkCGgAwVOQt/4kGAJwscBU0AGBeGgAwLw0AmJcGAMxLAwDOFvdDYQ0AmJcGAAz14geC4v5mkAYAjPW048dNgAYATEwDAAZb3p6GogEAp4qcgNiLA8hp/zKoTRZgQq2UFve+AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4liuXgCQWy2llLJevAo6aQDQr+6HKpDS7eoFAHnV/19CbOYAoNchASaBhMwBQKfjFGAqSEgDgE6u+7+ABgB96n7df6+BQSAfDQB6PQaBuh0aDPLxmTDQ58VVvwikYw4AmJcGAMxLA4BBvBOUkAYAY6y+FpSQBgB91sNJNQgkpAHAR7aN3wyQlAYAnX7t/m4PyEoDgF7r47EWCcjJPWJAP/8fkJ0GAJ+4V0ABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYJAfSlQj55pMcaAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=1539x1376>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictt['A03_00Aa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:32:09.988644Z",
     "iopub.status.busy": "2023-06-12T13:32:09.987852Z",
     "iopub.status.idle": "2023-06-12T13:32:09.993718Z",
     "shell.execute_reply": "2023-06-12T13:32:09.992674Z",
     "shell.execute_reply.started": "2023-06-12T13:32:09.988609Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/kaggle/input/multi-Hamamatsu-LG/Total\" ## Now importing the normal images themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:32:13.518599Z",
     "iopub.status.busy": "2023-06-12T13:32:13.518239Z",
     "iopub.status.idle": "2023-06-12T13:32:13.658301Z",
     "shell.execute_reply": "2023-06-12T13:32:13.657368Z",
     "shell.execute_reply.started": "2023-06-12T13:32:13.518570Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = os.listdir(data_path)\n",
    "image_names = [image.split(\".\")[0] for image in  all_data if image.split(\".\")[-1]==\"tiff\"]   ## Getting the name of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:32:55.402718Z",
     "iopub.status.busy": "2023-06-12T13:32:55.402341Z",
     "iopub.status.idle": "2023-06-12T13:32:55.410609Z",
     "shell.execute_reply": "2023-06-12T13:32:55.409688Z",
     "shell.execute_reply.started": "2023-06-12T13:32:55.402689Z"
    }
   },
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,image_path, images,feature_extractor):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            image_path (string): _Path of the Images_\n",
    "            images (_type_): _Array of name of images_\n",
    "            feature_extractor (_type_): _Image feature extractor for Segformer_\n",
    "        \"\"\"\n",
    "        \n",
    "        self.image_path = image_path\n",
    "        self.images = images\n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Returns:\n",
    "            _int_: _length of dataset_\n",
    "        \"\"\"\n",
    "        return len(self.images)        \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "\n",
    "        image_name = self.images[idx]\n",
    "        \n",
    "        image = Image.open(self.image_path +\"/\" +image_name +\".tiff\")  ## Image will be the actual image\n",
    "        segmentation_mask = dictt[image_name] ## Segmented Image will taken from the dictionary we created\n",
    "\n",
    "        image = image.convert('RGB')  ## Image will be converted to RGB to reduce size\n",
    "        \n",
    "        ## Encoding the data using feature extractor\n",
    "        encodings = self.feature_extractor(image,segmentation_mask,return_tensors = \"pt\")\n",
    "        \n",
    "        ## Removing the dimension of the batch\n",
    "        for k,v in encodings.items():\n",
    "            encodings[k] = v.squeeze_()  \n",
    "            \n",
    "        return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:32:56.541320Z",
     "iopub.status.busy": "2023-06-12T13:32:56.540627Z",
     "iopub.status.idle": "2023-06-12T13:32:56.548009Z",
     "shell.execute_reply": "2023-06-12T13:32:56.544969Z",
     "shell.execute_reply.started": "2023-06-12T13:32:56.541285Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import SegformerFeatureExtractor  ##  Get Feature Extractor\n",
    "\n",
    "\n",
    "feature_extractor = SegformerFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:32:57.902838Z",
     "iopub.status.busy": "2023-06-12T13:32:57.902473Z",
     "iopub.status.idle": "2023-06-12T13:32:57.907397Z",
     "shell.execute_reply": "2023-06-12T13:32:57.906444Z",
     "shell.execute_reply.started": "2023-06-12T13:32:57.902808Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SegmentationDataset(data_path, image_names,feature_extractor)   ## Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:33:02.409458Z",
     "iopub.status.busy": "2023-06-12T13:33:02.409084Z",
     "iopub.status.idle": "2023-06-12T13:33:02.903241Z",
     "shell.execute_reply": "2023-06-12T13:33:02.902090Z",
     "shell.execute_reply.started": "2023-06-12T13:33:02.409429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0, 120, 255])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataset:   ## Proving that only 3 possible colors exists. 0 for black, 255 for white. 120 for grey.\n",
    "    if (len(i['labels'].squeeze().unique()) >2):\n",
    "        print(i['labels'].squeeze().unique())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:33:04.696198Z",
     "iopub.status.busy": "2023-06-12T13:33:04.695427Z",
     "iopub.status.idle": "2023-06-12T13:33:04.744944Z",
     "shell.execute_reply": "2023-06-12T13:33:04.743815Z",
     "shell.execute_reply.started": "2023-06-12T13:33:04.696160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n",
      "torch.Size([512, 512])\n"
     ]
    }
   ],
   "source": [
    "for k,v in train_dataset[0].items():   ## These are the dimensions of items\n",
    "    print(v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:33:06.110707Z",
     "iopub.status.busy": "2023-06-12T13:33:06.109879Z",
     "iopub.status.idle": "2023-06-12T13:33:06.116013Z",
     "shell.execute_reply": "2023-06-12T13:33:06.114999Z",
     "shell.execute_reply.started": "2023-06-12T13:33:06.110672Z"
    }
   },
   "outputs": [],
   "source": [
    "id2label = {0:0,1:255, 2:120}   ## setting a number to each color\n",
    "label2id = {0:0,255:1, 120:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:33:08.569273Z",
     "iopub.status.busy": "2023-06-12T13:33:08.568577Z",
     "iopub.status.idle": "2023-06-12T13:33:12.838346Z",
     "shell.execute_reply": "2023-06-12T13:33:12.837477Z",
     "shell.execute_reply.started": "2023-06-12T13:33:08.569232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7cfc87e2bf4de4a316da583e02cc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/70.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf000a6b568d4fc8ad21f0138f828e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/14.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.batch_norm.bias', 'decode_head.linear_fuse.weight', 'decode_head.classifier.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.3.proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerForSemanticSegmentation  ## Importing the pretrained model\n",
    "model_name = \"nvidia/mit-b0\"\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(model_name,\n",
    "                                                         num_labels=3, \n",
    "                                                         id2label=id2label, \n",
    "                                                         label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialising Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:43:55.466089Z",
     "iopub.status.busy": "2023-06-12T13:43:55.465074Z",
     "iopub.status.idle": "2023-06-12T13:43:55.470825Z",
     "shell.execute_reply": "2023-06-12T13:43:55.469856Z",
     "shell.execute_reply.started": "2023-06-12T13:43:55.466053Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader ## Getting the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:43:56.579417Z",
     "iopub.status.busy": "2023-06-12T13:43:56.578703Z",
     "iopub.status.idle": "2023-06-12T13:43:56.583860Z",
     "shell.execute_reply": "2023-06-12T13:43:56.582954Z",
     "shell.execute_reply.started": "2023-06-12T13:43:56.579383Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16  ## Different batch sizes were tried, 16 turned out to be the most efficient with ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:43:58.197649Z",
     "iopub.status.busy": "2023-06-12T13:43:58.197279Z",
     "iopub.status.idle": "2023-06-12T13:43:58.203730Z",
     "shell.execute_reply": "2023-06-12T13:43:58.202617Z",
     "shell.execute_reply.started": "2023-06-12T13:43:58.197620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:43:59.247681Z",
     "iopub.status.busy": "2023-06-12T13:43:59.247327Z",
     "iopub.status.idle": "2023-06-12T13:43:59.253795Z",
     "shell.execute_reply": "2023-06-12T13:43:59.252780Z",
     "shell.execute_reply.started": "2023-06-12T13:43:59.247652Z"
    }
   },
   "outputs": [],
   "source": [
    "import random   ## Shuffling image names so model doesn't overfit\n",
    "random.shuffle(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:43:59.852020Z",
     "iopub.status.busy": "2023-06-12T13:43:59.851631Z",
     "iopub.status.idle": "2023-06-12T13:43:59.856886Z",
     "shell.execute_reply": "2023-06-12T13:43:59.856029Z",
     "shell.execute_reply.started": "2023-06-12T13:43:59.851989Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SegmentationDataset(data_path,image_names[:1100],feature_extractor) ## Taking 100 Images for training for now\n",
    "test_dataset =  SegmentationDataset(data_path,image_names[1100:1200],feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:44:00.533427Z",
     "iopub.status.busy": "2023-06-12T13:44:00.532728Z",
     "iopub.status.idle": "2023-06-12T13:44:00.539388Z",
     "shell.execute_reply": "2023-06-12T13:44:00.538344Z",
     "shell.execute_reply.started": "2023-06-12T13:44:00.533392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:44:01.095064Z",
     "iopub.status.busy": "2023-06-12T13:44:01.094693Z",
     "iopub.status.idle": "2023-06-12T13:44:01.099811Z",
     "shell.execute_reply": "2023-06-12T13:44:01.098832Z",
     "shell.execute_reply.started": "2023-06-12T13:44:01.095034Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,batch_size=16,shuffle=True)   ## preparing test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:44:01.751628Z",
     "iopub.status.busy": "2023-06-12T13:44:01.751274Z",
     "iopub.status.idle": "2023-06-12T13:44:01.756394Z",
     "shell.execute_reply": "2023-06-12T13:44:01.755200Z",
     "shell.execute_reply.started": "2023-06-12T13:44:01.751600Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)   ## Preparing train dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:44:02.191092Z",
     "iopub.status.busy": "2023-06-12T13:44:02.190716Z",
     "iopub.status.idle": "2023-06-12T13:44:02.197149Z",
     "shell.execute_reply": "2023-06-12T13:44:02.196075Z",
     "shell.execute_reply.started": "2023-06-12T13:44:02.191061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:44:03.153629Z",
     "iopub.status.busy": "2023-06-12T13:44:03.153269Z",
     "iopub.status.idle": "2023-06-12T13:44:04.917363Z",
     "shell.execute_reply": "2023-06-12T13:44:04.916457Z",
     "shell.execute_reply.started": "2023-06-12T13:44:03.153601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd30fc01e8104446940a9d2c50f03c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_metric   \n",
    "\n",
    "metric = load_metric(\"mean_iou\")\n",
    "#metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:44:32.010568Z",
     "iopub.status.busy": "2023-06-12T13:44:32.009869Z",
     "iopub.status.idle": "2023-06-12T13:44:32.014890Z",
     "shell.execute_reply": "2023-06-12T13:44:32.013994Z",
     "shell.execute_reply.started": "2023-06-12T13:44:32.010536Z"
    }
   },
   "outputs": [],
   "source": [
    "   ## Final path decided\n",
    "path1 = \"/kaggle/working/Hamamatsu_LG_Multi_loss.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T13:44:33.891512Z",
     "iopub.status.busy": "2023-06-12T13:44:33.890816Z",
     "iopub.status.idle": "2023-06-12T13:44:38.290425Z",
     "shell.execute_reply": "2023-06-12T13:44:38.289341Z",
     "shell.execute_reply.started": "2023-06-12T13:44:33.891478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch   ## Optimizer made.\n",
    "from torch import nn\n",
    "#from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00006)  ## Learning rate\n",
    "# move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") ## GPU used\n",
    "model.to(device)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx = 100  ## Max decides because obviously metrics will be lower than this. \n",
    "model.train()\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    metric = load_metric(\"mean_iou\")\n",
    "    \n",
    "    print(\"Epoch:\", epoch)\n",
    "    for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # get the inputs;\n",
    "        pixel_values = batch[\"pixel_values\"].cuda()\n",
    "        labels = batch[\"labels\"].cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()    \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss, logits = outputs.loss, outputs.logits\n",
    "        \n",
    "        loss.backward()  ## This is backpropogation\n",
    "        optimizer.step()   \n",
    "\n",
    "        # evaluate\n",
    "        \n",
    "    with torch.no_grad():   ## No gradient changing\n",
    "        \n",
    "        for idx, batch in enumerate(tqdm(test_dataloader)):   ## Testing accuracy\n",
    "    # get the inputs;\n",
    "            pixel_values1 = batch[\"pixel_values\"].cuda()\n",
    "            labels1 = batch[\"labels\"].cuda()\n",
    "            outputs1 = model(pixel_values=pixel_values1, labels=labels1)\n",
    "            loss, logits = outputs1.loss, outputs1.logits\n",
    "            upsampled_logits = nn.functional.interpolate(logits, size=labels1.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            predicted = upsampled_logits.argmax(dim=1)\n",
    "            metric.add_batch(predictions=predicted.detach().cpu().numpy(), references=labels1.detach().cpu().numpy())\n",
    "        \n",
    "        # note that the metric expects predictions + labels as numpy arrays\n",
    "\n",
    "        # let's print loss and metrics every 100 batches\n",
    "        #predictions=predicted.detach().cpu().numpy()\n",
    "\n",
    "        #metrics = metric._compute(predictions=predicted.detach().cpu().numpy(), references=labels1.detach().cpu().numpy(),num_labels=len(id2label), \n",
    "                               #ignore_index=255,\n",
    "                               #reduce_labels=False, # we've already reduced the labels before)\n",
    "                                # )\n",
    "        metrics = metric.compute(num_labels=len(id2label), ignore_index=255, reduce_labels=False)\n",
    "        ars = loss.item()  \n",
    "        print(\"Loss:\", ars)\n",
    "        print(\"Mean_iou:\", metrics[\"mean_iou\"])\n",
    "        print(\"Mean accuracy:\", metrics[\"mean_accuracy\"])\n",
    "\n",
    "        if maxx < ars:   ## \n",
    "            maxx = ars  ## Lowest loss saved\n",
    "            torch.save(model, path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
